"""
SAHI validation module.

This module provides SAHI-based validation with sliced inference for YOLO models.
"""

import json
import sys
import time
import csv
from pathlib import Path
from dataclasses import dataclass, field
from typing import Optional, Dict, Any
from collections import defaultdict, Counter

import numpy as np
from tqdm import tqdm

from sahi import AutoDetectionModel
from sahi.predict import get_sliced_prediction, get_prediction
from sahi.scripts.coco_evaluation import evaluate as coco_evaluate
from sahi.scripts.coco_error_analysis import analyse as coco_analyse
from sahi.utils.coco import Coco

from validation.utils.coco_converter import YOLOToCOCOConverter, get_incremental_dir


@dataclass
class SAHIValidationConfig:
    """SAHI validation configuration"""
    
    model_path: str = "runs/train/train12/weights/best.pt"
    yolo_dataset_dir: Optional[str] = None
    dataset_json_path: Optional[str] = None
    image_dir: Optional[str] = None
    output_dir: str = "runs/val"
    experiment_name: str = "sahi_val"
    auto_increment: bool = True
    
    # Model parameters
    confidence_threshold: float = 0.25
    device: str = "0"
    image_size: int = 640
    
    # Sliced prediction
    use_sliced_prediction: bool = True
    compare_with_standard: bool = False
    slice_height: int = 512
    slice_width: int = 512
    overlap_height_ratio: float = 0.5
    overlap_width_ratio: float = 0.5
    
    # Postprocessing
    postprocess_type: str = "GREEDYNMM"
    postprocess_match_metric: str = "IOS"
    postprocess_match_threshold: float = 0.5
    postprocess_class_agnostic: bool = False
    
    # Evaluation
    iou_thrs: Optional[list[float]] = None
    max_detections: int = 500
    classwise: bool = False
    areas: list[int] = field(default_factory=lambda: [1024, 9216, 10000000000])
    
    # Visualization
    export_visuals: bool = False
    visual_export_dir: Optional[str] = None
    visual_bbox_thickness: int = 2
    visual_text_size: float = 0.5
    visual_hide_labels: bool = False
    visual_hide_conf: bool = False
    max_visual_samples: Optional[int] = None
    
    # Error analysis
    error_analysis: bool = False
    
    # Prediction only mode
    predict_only: bool = False
    
    # CSV export
    save_csv: bool = False
    csv_path: Optional[str] = None
    
    # Other
    verbose: int = 1
    
    def __post_init__(self):
        """Ë®≠ÂÆö„ÅÆÊ§úË®º"""
        if not Path(self.model_path).exists():
            raise FileNotFoundError(f"„É¢„Éá„É´„Éï„Ç°„Ç§„É´„ÅåË¶ã„Å§„Åã„Çä„Åæ„Åõ„Çì: {self.model_path}")
        
        # Ëá™Âãï„Ç§„É≥„ÇØ„É™„É°„É≥„ÉàÊ©üËÉΩ
        if self.auto_increment:
            self.output_dir = str(get_incremental_dir(self.output_dir, self.experiment_name))
        
        # YOLOÂΩ¢Âºè„ÅÆÂ†¥Âêà„ÅØÂ§âÊèõ„ÇíÂÆüË°å
        if self.yolo_dataset_dir:
            if not Path(self.yolo_dataset_dir).exists():
                raise FileNotFoundError(f"YOLO„Éá„Éº„Çø„Çª„ÉÉ„Éà„Éá„Ç£„É¨„ÇØ„Éà„É™„ÅåË¶ã„Å§„Åã„Çä„Åæ„Åõ„Çì: {self.yolo_dataset_dir}")
            
            # ‰∏ÄÊôÇÁöÑ„Å™COCO JSON„Éï„Ç°„Ç§„É´„Çí‰ΩúÊàê
            if self.dataset_json_path is None:
                temp_dir = Path(self.output_dir) / "temp"
                temp_dir.mkdir(parents=True, exist_ok=True)
                self.dataset_json_path = str(temp_dir / "dataset.json")
            
            # Â§âÊèõ„ÇíÂÆüË°åÔºà„Åæ„Å†Â§âÊèõ„Åï„Çå„Å¶„ÅÑ„Å™„ÅÑÂ†¥Âêà„ÄÅ„Åæ„Åü„ÅØÂè§„ÅÑÂΩ¢Âºè„ÅÆÂ†¥ÂêàÔºâ
            need_conversion = True
            if Path(self.dataset_json_path).exists():
                # Êó¢Â≠ò„ÅÆJSON„Éï„Ç°„Ç§„É´„Çí„ÉÅ„Çß„ÉÉ„ÇØ„Åó„Å¶„ÄÅÂè§„ÅÑÂΩ¢Âºè„Åã„Å©„ÅÜ„ÅãÁ¢∫Ë™ç
                try:
                    with open(self.dataset_json_path, "r", encoding="utf-8") as f:
                        existing_json = json.load(f)
                    # file_name„Å´„Çπ„É©„ÉÉ„Ç∑„É•„ÅåÂê´„Åæ„Çå„Å¶„ÅÑ„ÇãÂ†¥Âêà„ÅØÂè§„ÅÑÂΩ¢Âºè
                    if "images" in existing_json and len(existing_json["images"]) > 0:
                        first_file_name = existing_json["images"][0].get("file_name", "")
                        if "/" in first_file_name or "\\" in first_file_name:
                            # Âè§„ÅÑÂΩ¢Âºè„Å™„ÅÆ„ÅßÂâäÈô§„Åó„Å¶ÂÜçÁîüÊàê
                            if self.verbose >= 1:
                                print(f"Âè§„ÅÑÂΩ¢Âºè„ÅÆCOCO JSON„ÇíÊ§úÂá∫„Åó„Åæ„Åó„Åü„ÄÇÂÜçÁîüÊàê„Åó„Åæ„Åô: {self.dataset_json_path}")
                            Path(self.dataset_json_path).unlink()
                        else:
                            # Êñ∞„Åó„ÅÑÂΩ¢Âºè„Å™„ÅÆ„ÅßÂÜçÁîüÊàê‰∏çË¶Å
                            need_conversion = False
                except Exception as e:
                    if self.verbose >= 1:
                        print(f"Êó¢Â≠ò„ÅÆJSON„Éï„Ç°„Ç§„É´„ÅÆË™≠„ÅøËæº„Åø„Ç®„É©„Éº: {e}„ÄÇÂÜçÁîüÊàê„Åó„Åæ„Åô„ÄÇ")
            
            if need_conversion:
                if self.verbose >= 1:
                    print(f"YOLOÂΩ¢Âºè„Åã„ÇâCOCOÂΩ¢Âºè„Å´Â§âÊèõ‰∏≠...")
                converter = YOLOToCOCOConverter(self.yolo_dataset_dir, split="val")
                if self.verbose >= 1:
                    print(f"  ‰ΩøÁî®„Åô„ÇãYAML: {converter.data_yaml_path.name}")
                self.dataset_json_path = converter.convert(self.dataset_json_path)
            
            # ÁîªÂÉè„Éá„Ç£„É¨„ÇØ„Éà„É™„ÇíË®≠ÂÆö
            if self.image_dir is None:
                self.image_dir = str(Path(self.yolo_dataset_dir) / "images" / "val")
        else:
            # COCOÂΩ¢Âºè„ÅÆÂ†¥Âêà
            if self.dataset_json_path and not Path(self.dataset_json_path).exists():
                raise FileNotFoundError(f"„Éá„Éº„Çø„Çª„ÉÉ„ÉàJSON„ÅåË¶ã„Å§„Åã„Çä„Åæ„Åõ„Çì: {self.dataset_json_path}")
            
            if self.image_dir and not Path(self.image_dir).exists():
                raise FileNotFoundError(f"ÁîªÂÉè„Éá„Ç£„É¨„ÇØ„Éà„É™„ÅåË¶ã„Å§„Åã„Çä„Åæ„Åõ„Çì: {self.image_dir}")
        
        # ÂèØË¶ñÂåñ„Éá„Ç£„É¨„ÇØ„Éà„É™„ÅÆË®≠ÂÆö
        if self.export_visuals:
            if self.visual_export_dir is None:
                self.visual_export_dir = str(Path(self.output_dir) / "visuals")
            Path(self.visual_export_dir).mkdir(parents=True, exist_ok=True)


class SAHISegmentationValidator:
    """SAHI„Çí‰ΩøÁî®„Åó„Åü„Çª„Ç∞„É°„É≥„ÉÜ„Éº„Ç∑„Éß„É≥validation„ÇØ„É©„Çπ"""

    def __init__(self, config: SAHIValidationConfig):
        """
        Args:
            config: SAHIValidationConfig
                ValidationË®≠ÂÆö
        """
        self.config = config
        self.detection_model: Optional[AutoDetectionModel] = None
        self.coco: Optional[Coco] = None
        self.predictions_json: list[dict] = []

    def load_model(self) -> None:
        """„É¢„Éá„É´„ÇíË™≠„ÅøËæº„ÇÄ"""
        if self.config.verbose >= 1:
            print(f"„É¢„Éá„É´„ÇíË™≠„ÅøËæº„Åø‰∏≠: {self.config.model_path}")

        self.detection_model = AutoDetectionModel.from_pretrained(
            model_type="ultralytics",
            model_path=self.config.model_path,
            confidence_threshold=self.config.confidence_threshold,
            device=self.config.device,
            load_at_init=True,
            image_size=self.config.image_size,
        )

        # „Çª„Ç∞„É°„É≥„ÉÜ„Éº„Ç∑„Éß„É≥„É¢„Éá„É´„ÅãÁ¢∫Ë™ç
        if not self.detection_model.has_mask:
            raise ValueError(
                "ÊåáÂÆö„Åï„Çå„Åü„É¢„Éá„É´„ÅØ„Çª„Ç∞„É°„É≥„ÉÜ„Éº„Ç∑„Éß„É≥„É¢„Éá„É´„Åß„ÅØ„ÅÇ„Çä„Åæ„Åõ„Çì„ÄÇ"
                "„Çª„Ç∞„É°„É≥„ÉÜ„Éº„Ç∑„Éß„É≥„É¢„Éá„É´Ôºà‰æã: yolo11n-seg.ptÔºâ„Çí‰ΩøÁî®„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ"
            )

        if self.config.verbose >= 1:
            print("„É¢„Éá„É´„ÅÆË™≠„ÅøËæº„Åø„ÅåÂÆå‰∫Ü„Åó„Åæ„Åó„Åü")

    def load_dataset(self) -> None:
        """„Éá„Éº„Çø„Çª„ÉÉ„Éà„ÇíË™≠„ÅøËæº„ÇÄ"""
        if self.config.verbose >= 1:
            print(f"„Éá„Éº„Çø„Çª„ÉÉ„Éà„ÇíË™≠„ÅøËæº„Åø‰∏≠: {self.config.dataset_json_path}")

        self.coco = Coco.from_coco_dict_or_path(self.config.dataset_json_path)

        if self.config.verbose >= 1:
            print(f"„Éá„Éº„Çø„Çª„ÉÉ„ÉàË™≠„ÅøËæº„ÅøÂÆå‰∫Ü: {len(self.coco.images)}Êûö„ÅÆÁîªÂÉè")

    def predict_images(self) -> None:
        """ÁîªÂÉè„Å´ÂØæ„Åó„Å¶Êé®Ë´ñ„ÇíÂÆüË°å"""
        if self.detection_model is None:
            raise RuntimeError("„É¢„Éá„É´„ÅåË™≠„ÅøËæº„Åæ„Çå„Å¶„ÅÑ„Åæ„Åõ„Çì„ÄÇload_model()„ÇíÂÖà„Å´ÂÆüË°å„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ")
        if self.coco is None:
            raise RuntimeError("„Éá„Éº„Çø„Çª„ÉÉ„Éà„ÅåË™≠„ÅøËæº„Åæ„Çå„Å¶„ÅÑ„Åæ„Åõ„Çì„ÄÇload_dataset()„ÇíÂÖà„Å´ÂÆüË°å„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ")

        if self.config.verbose >= 1:
            print("Êé®Ë´ñ„ÇíÈñãÂßã„Åó„Åæ„Åô...")

        self.predictions_json = []
        self.detection_stats = defaultdict(lambda: defaultdict(int))  # ÁîªÂÉè„Åî„Å®„ÅÆ„ÇØ„É©„ÇπÂà•„Ç´„Ç¶„É≥„Éà
        
        image_paths = [
            str(Path(self.config.image_dir) / coco_image.file_name)
            for coco_image in self.coco.images
        ]

        iterator = tqdm(enumerate(self.coco.images), total=len(self.coco.images), disable=self.config.verbose == 0)

        success_count = 0
        error_count = 0
        visual_count = 0  # ÂèØË¶ñÂåñ„Åó„ÅüÁîªÂÉè„ÅÆÊï∞

        for img_idx, coco_image in iterator:
            image_path = image_paths[img_idx]

            if not Path(image_path).exists():
                if self.config.verbose >= 1:
                    tqdm.write(f"Ë≠¶Âëä: ÁîªÂÉè„ÅåË¶ã„Å§„Åã„Çä„Åæ„Åõ„Çì: {image_path}")
                error_count += 1
                continue

            try:
                # Ë©≥Á¥∞„É¢„Éº„Éâ„ÅßÂá¶ÁêÜ‰∏≠„ÅÆÁîªÂÉè„ÇíË°®Á§∫
                if self.config.verbose >= 2:
                    tqdm.write(f"Âá¶ÁêÜ‰∏≠: {Path(image_path).name}")
                # Êé®Ë´ñÂÆüË°å
                if self.config.use_sliced_prediction:
                    prediction_result = get_sliced_prediction(
                        image=image_path,
                        detection_model=self.detection_model,
                        slice_height=self.config.slice_height,
                        slice_width=self.config.slice_width,
                        overlap_height_ratio=self.config.overlap_height_ratio,
                        overlap_width_ratio=self.config.overlap_width_ratio,
                        perform_standard_pred=True,
                        postprocess_type=self.config.postprocess_type,
                        postprocess_match_metric=self.config.postprocess_match_metric,
                        postprocess_match_threshold=self.config.postprocess_match_threshold,
                        postprocess_class_agnostic=self.config.postprocess_class_agnostic,
                        verbose=0,
                    )
                else:
                    prediction_result = get_prediction(
                        image=image_path,
                        detection_model=self.detection_model,
                        shift_amount=[0, 0],
                        full_shape=None,
                        postprocess=None,
                        verbose=0,
                    )

                # COCOÂΩ¢Âºè„Å´Â§âÊèõ„Å®„Ç´„Ç¶„É≥„Éà
                image_name = Path(image_path).name
                for object_prediction in prediction_result.object_prediction_list:
                    coco_prediction = object_prediction.to_coco_prediction(image_id=coco_image.id)
                    coco_prediction_json = coco_prediction.json
                    if coco_prediction_json.get("bbox") or coco_prediction_json.get("segmentation"):
                        self.predictions_json.append(coco_prediction_json)
                        # „ÇØ„É©„Çπ„Åî„Å®„ÅÆ„Ç´„Ç¶„É≥„Éà
                        class_name = object_prediction.category.name
                        self.detection_stats[image_name][class_name] += 1
                        self.detection_stats[image_name]['total'] += 1
                
                # ÂèØË¶ñÂåñ„ÅÆÂÆüË°å
                if self.config.export_visuals:
                    # max_visual_samples„ÅåË®≠ÂÆö„Åï„Çå„Å¶„ÅÑ„ÇãÂ†¥Âêà„ÄÅ„Åù„ÅÆÊï∞„Åæ„ÅßÂèØË¶ñÂåñ
                    should_visualize = (
                        self.config.max_visual_samples is None or
                        visual_count < self.config.max_visual_samples
                    )
                    
                    if should_visualize:
                        try:
                            # ÂèØË¶ñÂåñÁî®„ÅÆ„Éï„Ç°„Ç§„É´Âêç„ÇíÁîüÊàêÔºàÊã°ÂºµÂ≠ê„Å™„Åó„ÄÅexport_visuals„ÅåËá™ÂãïÁöÑ„Å´.png„ÇíËøΩÂä†Ôºâ
                            image_filename = Path(image_path).stem
                            visual_filename = f"{image_filename}_prediction"
                            
                            # ÂèØË¶ñÂåñ„ÇíÂÆüË°å„Åó„Å¶‰øùÂ≠ò
                            prediction_result.export_visuals(
                                export_dir=self.config.visual_export_dir,
                                file_name=visual_filename,
                                text_size=self.config.visual_text_size,
                                rect_th=self.config.visual_bbox_thickness,
                                hide_labels=self.config.visual_hide_labels,
                                hide_conf=self.config.visual_hide_conf,
                            )
                            
                            visual_count += 1
                            
                            if self.config.verbose >= 2:
                                tqdm.write(f"ÂèØË¶ñÂåñ‰øùÂ≠ò: {visual_filename}.png")
                        except Exception as e:
                            # „Ç®„É©„Éº„ÇíÂ∏∏„Å´Ë°®Á§∫Ôºàverbose >= 1Ôºâ
                            if self.config.verbose >= 1:
                                tqdm.write(f"ÂèØË¶ñÂåñ„Ç®„É©„Éº {Path(image_path).name}: {str(e)}")
                            if self.config.verbose >= 2:
                                import traceback
                                tqdm.write(traceback.format_exc())
                
                success_count += 1
                
            except KeyboardInterrupt:
                if self.config.verbose >= 1:
                    print("\n\nÊé®Ë´ñ„Åå‰∏≠Êñ≠„Åï„Çå„Åæ„Åó„ÅüÔºàCtrl+CÔºâ")
                    print(f"Âá¶ÁêÜÊ∏à„Åø: {success_count + error_count}/{len(self.coco.images)}Êûö")
                raise
            except Exception as e:
                error_count += 1
                error_msg = f"„Ç®„É©„Éº: ÁîªÂÉè {Path(image_path).name} „ÅÆÊé®Ë´ñ„Å´Â§±Êïó„Åó„Åæ„Åó„Åü: {str(e)}"
                print(f"\n{error_msg}", file=sys.stderr)
                sys.stderr.flush()
                if self.config.verbose >= 2:
                    import traceback
                    print(traceback.format_exc(), file=sys.stderr)
                    sys.stderr.flush()
                continue

        if self.config.verbose >= 1:
            print(f"\nÊé®Ë´ñÂÆå‰∫Ü: {len(self.predictions_json)}ÂÄã„ÅÆ‰∫àÊ∏¨ÁµêÊûú")
            print(f"ÊàêÂäü: {success_count}Êûö, „Ç®„É©„Éº: {error_count}Êûö")
            if self.config.export_visuals:
                print(f"ÂèØË¶ñÂåñ: {visual_count}Êûö (‰øùÂ≠òÂÖà: {self.config.visual_export_dir})")
        
        # CSV‰øùÂ≠ò
        if self.config.save_csv:
            self.save_detection_csv()

    def save_detection_csv(self) -> None:
        """Ê§úÂá∫ÁµêÊûú„ÇíCSV„Éï„Ç°„Ç§„É´„Å´‰øùÂ≠ò"""
        output_path = Path(self.config.output_dir)
        output_path.mkdir(parents=True, exist_ok=True)
        
        csv_file = output_path / (self.config.csv_path if self.config.csv_path else "detection_counts.csv")
        
        # ÂÖ®„ÇØ„É©„ÇπÂêç„ÇíÂèéÈõÜ
        all_classes = set()
        for image_stats in self.detection_stats.values():
            all_classes.update(k for k in image_stats.keys() if k != 'total')
        all_classes = sorted(all_classes)
        
        # CSV„Éò„ÉÉ„ÉÄ„Éº
        fieldnames = ['image_name', 'total'] + all_classes
        
        with open(csv_file, 'w', newline='', encoding='utf-8') as f:
            writer = csv.DictWriter(f, fieldnames=fieldnames)
            writer.writeheader()
            
            # ÂêÑÁîªÂÉè„ÅÆÊ§úÂá∫Êï∞„ÇíÊõ∏„ÅçËæº„Åø
            for image_name in sorted(self.detection_stats.keys()):
                row = {'image_name': image_name}
                row['total'] = self.detection_stats[image_name].get('total', 0)
                for class_name in all_classes:
                    row[class_name] = self.detection_stats[image_name].get(class_name, 0)
                writer.writerow(row)
            
            # ÂêàË®àË°å„ÇíËøΩÂä†
            total_row = {'image_name': 'TOTAL'}
            total_row['total'] = sum(stats.get('total', 0) for stats in self.detection_stats.values())
            for class_name in all_classes:
                total_row[class_name] = sum(stats.get(class_name, 0) for stats in self.detection_stats.values())
            writer.writerow(total_row)
        
        if self.config.verbose >= 1:
            print(f"üìä Ê§úÂá∫„Ç´„Ç¶„É≥„ÉàCSV„Çí‰øùÂ≠ò„Åó„Åæ„Åó„Åü: {csv_file}")
            print(f"   Á∑èÊ§úÂá∫Êï∞: {total_row['total']}ÂÄã")
            print(f"   ÁîªÂÉèÊï∞: {len(self.detection_stats)}Êûö")

    def save_predictions(self) -> str:
        """‰∫àÊ∏¨ÁµêÊûú„ÇíJSON„Éï„Ç°„Ç§„É´„Å´‰øùÂ≠ò"""
        output_path = Path(self.config.output_dir)
        output_path.mkdir(parents=True, exist_ok=True)

        predictions_file = output_path / "predictions.json"
        with open(predictions_file, "w", encoding="utf-8") as f:
            json.dump(self.predictions_json, f, indent=2)

        if self.config.verbose >= 1:
            print(f"‰∫àÊ∏¨ÁµêÊûú„Çí‰øùÂ≠ò„Åó„Åæ„Åó„Åü: {predictions_file}")

        return str(predictions_file)

    def evaluate(self, predictions_file: str) -> dict:
        """COCOË©ï‰æ°„ÇíÂÆüË°åÔºàPrecision/RecallÂê´„ÇÄÔºâ"""
        if self.config.verbose >= 1:
            print("Ë©ï‰æ°„ÇíÂÆüË°å‰∏≠...")

        # Âü∫Êú¨ÁöÑ„Å™COCOË©ï‰æ°
        result = coco_evaluate(
            dataset_json_path=self.config.dataset_json_path,
            result_json_path=predictions_file,
            out_dir=self.config.output_dir,
            type="segm",  # „Çª„Ç∞„É°„É≥„ÉÜ„Éº„Ç∑„Éß„É≥Ë©ï‰æ°
            classwise=self.config.classwise,
            max_detections=self.config.max_detections,
            iou_thrs=self.config.iou_thrs,
            areas=self.config.areas,
            return_dict=True,
        )

        # Precision/Recall„ÇíË®àÁÆó
        pr_metrics = self._calculate_precision_recall(predictions_file)
        result['eval_results'].update(pr_metrics)

        if self.config.verbose >= 1:
            print(f"Ë©ï‰æ°ÁµêÊûú„Çí‰øùÂ≠ò„Åó„Åæ„Åó„Åü: {result['export_path']}")
        
        # „Ç®„É©„ÉºËß£Êûê„Éó„É≠„ÉÉ„Éà„ÇíÁîüÊàê
        if self.config.error_analysis:
            if self.config.verbose >= 1:
                print("\n„Ç®„É©„ÉºËß£Êûê„Éó„É≠„ÉÉ„Éà„ÇíÁîüÊàê‰∏≠...")
            
            try:
                error_analysis_result = coco_analyse(
                    dataset_json_path=self.config.dataset_json_path,
                    result_json_path=predictions_file,
                    out_dir=self.config.output_dir,
                    type="segm",
                    no_extraplots=False,  # ËøΩÂä†„ÅÆ„Éó„É≠„ÉÉ„Éà„ÇÇÁîüÊàê
                    areas=self.config.areas,
                    max_detections=self.config.max_detections,
                    return_dict=True,
                )
                
                if self.config.verbose >= 1:
                    print(f"„Ç®„É©„ÉºËß£Êûê„Éó„É≠„ÉÉ„Éà„Çí‰øùÂ≠ò„Åó„Åæ„Åó„Åü: {self.config.output_dir}")
                    print("\n[„Ç®„É©„ÉºËß£Êûê„ÅÆË¶ãÊñπ]")
                    print("  C75: 0.75 IoUÈñæÂÄ§„Åß„ÅÆÁµêÊûú")
                    print("  C50: 0.50 IoUÈñæÂÄ§„Åß„ÅÆÁµêÊûú")
                    print("  Loc: „É≠„Éº„Ç´„É™„Çº„Éº„Ç∑„Éß„É≥„Ç®„É©„Éº„ÇíÁÑ°Ë¶ñ„Åó„ÅüÁµêÊûú")
                    print("  Sim: „Çπ„Éº„Éë„Éº„Ç´„ÉÜ„Ç¥„É™„ÅÆË™§Ê§úÂá∫„ÇíÁÑ°Ë¶ñ„Åó„ÅüÁµêÊûú")
                    print("  Oth: „Åô„Åπ„Å¶„ÅÆ„Ç´„ÉÜ„Ç¥„É™Ê∑∑Âêå„ÇíÁÑ°Ë¶ñ„Åó„ÅüÁµêÊûú")
                    print("  BG:  „Åô„Åπ„Å¶„ÅÆÂÅΩÈôΩÊÄß„ÇíÁÑ°Ë¶ñ„Åó„ÅüÁµêÊûú")
                    print("  FN:  „Åô„Åπ„Å¶„ÅÆÂÅΩÈô∞ÊÄß„ÇíÁÑ°Ë¶ñ„Åó„ÅüÁµêÊûú")
                    print("\n[ÊîπÂñÑ„ÅÆ„Éù„ÉÜ„É≥„Ç∑„É£„É´]")
                    print("  C75-C50, C50-Loc: „Çà„ÇäÊ≠£Á¢∫„Å™BBox‰∫àÊ∏¨„Åß„ÅÆÊîπÂñÑÂèØËÉΩÊÄß")
                    print("  Loc-Sim: „Çπ„Éº„Éë„Éº„Ç´„ÉÜ„Ç¥„É™Ê∑∑Âêå„ÅÆ‰øÆÊ≠£„Åß„ÅÆÊîπÂñÑÂèØËÉΩÊÄß")
                    print("  Loc-Oth: „Ç´„ÉÜ„Ç¥„É™Ê∑∑Âêå„ÅÆ‰øÆÊ≠£„Åß„ÅÆÊîπÂñÑÂèØËÉΩÊÄß")
                    print("  Oth-BG:  ÂÅΩÈôΩÊÄß„ÅÆ‰øÆÊ≠£„Åß„ÅÆÊîπÂñÑÂèØËÉΩÊÄß")
                    print("  BG-FN:   ÂÅΩÈô∞ÊÄß„ÅÆ‰øÆÊ≠£„Åß„ÅÆÊîπÂñÑÂèØËÉΩÊÄß")
                
                result['error_analysis'] = error_analysis_result
            except Exception as e:
                if self.config.verbose >= 1:
                    print(f"Ë≠¶Âëä: „Ç®„É©„ÉºËß£Êûê„Å´Â§±Êïó„Åó„Åæ„Åó„Åü: {e}")
                    if self.config.verbose >= 2:
                        import traceback
                        traceback.print_exc()

        return result
    
    def _calculate_precision_recall(self, predictions_file: str) -> dict:
        """Precision/Recall„ÇíË®àÁÆóÔºàUltralytics„Çπ„Çø„Ç§„É´Ôºâ"""
        from pycocotools.coco import COCO
        from pycocotools.cocoeval import COCOeval
        
        # COCOË©ï‰æ°„ÅÆÊ∫ñÂÇô
        coco_gt = COCO(self.config.dataset_json_path)
        coco_dt = coco_gt.loadRes(predictions_file)
        
        # „Çª„Ç∞„É°„É≥„ÉÜ„Éº„Ç∑„Éß„É≥Ë©ï‰æ°
        coco_eval = COCOeval(coco_gt, coco_dt, 'segm')
        coco_eval.params.maxDets = [self.config.max_detections]
        coco_eval.evaluate()
        coco_eval.accumulate()
        
        # Precision/Recall„ÇíÂèñÂæó
        # precision: [TxRxKxAxM] - T=IoUÈñæÂÄ§, R=RecallÈñæÂÄ§, K=„Ç´„ÉÜ„Ç¥„É™, A=„Ç®„É™„Ç¢, M=maxDets
        precision = coco_eval.eval['precision']
        recall = coco_eval.eval['recall']
        
        # IoU=0.5„Åß„ÅÆPrecision/RecallÔºàmAP50Áõ∏ÂΩìÔºâ
        # IoUÈñæÂÄ§„ÅÆ„Ç§„É≥„Éá„ÉÉ„ÇØ„Çπ: 0=0.5, 5=0.75
        iou_50_idx = 0  # IoU=0.5
        
        # ÂÖ®„Ç´„ÉÜ„Ç¥„É™„ÄÅÂÖ®„Ç®„É™„Ç¢„ÄÅmaxDets„Åß„ÅÆÂπ≥Âùá
        # precision[iou_idx, :, :, area_idx, maxdet_idx]
        p_iou50 = precision[iou_50_idx, :, :, 0, 0]  # area=all
        p_iou50 = p_iou50[p_iou50 > -1]  # -1„ÇíÈô§Â§ñ
        precision_50 = np.mean(p_iou50) if len(p_iou50) > 0 else 0.0
        
        # IoU=0.5:0.95„Åß„ÅÆÂπ≥ÂùáPrecision
        p_all = precision[:, :, :, 0, 0]  # ÂÖ®IoU„ÄÅarea=all
        p_all = p_all[p_all > -1]
        precision_avg = np.mean(p_all) if len(p_all) > 0 else 0.0
        
        # RecallÔºàIoU=0.5:0.95Ôºâ
        # recall: [TxKxAxM]
        r_all = recall[:, :, 0, 0]  # ÂÖ®IoU„ÄÅarea=all
        r_all = r_all[r_all > -1]
        recall_avg = np.mean(r_all) if len(r_all) > 0 else 0.0
        
        # IoU=0.5„Åß„ÅÆRecall
        r_iou50 = recall[iou_50_idx, :, 0, 0]
        r_iou50 = r_iou50[r_iou50 > -1]
        recall_50 = np.mean(r_iou50) if len(r_iou50) > 0 else 0.0
        
        # „Éú„ÉÉ„ÇØ„ÇπË©ï‰æ°„ÇÇËøΩÂä†
        coco_eval_box = COCOeval(coco_gt, coco_dt, 'bbox')
        coco_eval_box.params.maxDets = [self.config.max_detections]
        coco_eval_box.evaluate()
        coco_eval_box.accumulate()
        
        precision_box = coco_eval_box.eval['precision']
        recall_box = coco_eval_box.eval['recall']
        
        p_box_iou50 = precision_box[iou_50_idx, :, :, 0, 0]
        p_box_iou50 = p_box_iou50[p_box_iou50 > -1]
        precision_box_50 = np.mean(p_box_iou50) if len(p_box_iou50) > 0 else 0.0
        
        p_box_all = precision_box[:, :, :, 0, 0]
        p_box_all = p_box_all[p_box_all > -1]
        precision_box_avg = np.mean(p_box_all) if len(p_box_all) > 0 else 0.0
        
        r_box_all = recall_box[:, :, 0, 0]
        r_box_all = r_box_all[r_box_all > -1]
        recall_box_avg = np.mean(r_box_all) if len(r_box_all) > 0 else 0.0
        
        r_box_iou50 = recall_box[iou_50_idx, :, 0, 0]
        r_box_iou50 = r_box_iou50[r_box_iou50 > -1]
        recall_box_50 = np.mean(r_box_iou50) if len(r_box_iou50) > 0 else 0.0
        
        return {
            # „Çª„Ç∞„É°„É≥„ÉÜ„Éº„Ç∑„Éß„É≥ÔºàMaskÔºâ
            "segm_precision": precision_avg,
            "segm_recall": recall_avg,
            "segm_precision50": precision_50,
            "segm_recall50": recall_50,
            # „Éê„Ç¶„É≥„Éá„Ç£„É≥„Ç∞„Éú„ÉÉ„ÇØ„ÇπÔºàBoxÔºâ
            "bbox_precision": precision_box_avg,
            "bbox_recall": recall_box_avg,
            "bbox_precision50": precision_box_50,
            "bbox_recall50": recall_box_50,
        }

    def run(self) -> dict:
        """Validation„ÇíÂÆüË°å"""
        start_time = time.time()

        try:
            # „É¢„Éá„É´Ë™≠„ÅøËæº„Åø
            self.load_model()

            # „Éá„Éº„Çø„Çª„ÉÉ„ÉàË™≠„ÅøËæº„Åø
            self.load_dataset()

            # Êé®Ë´ñÂÆüË°å
            self.predict_images()

            # ‰∫àÊ∏¨ÁµêÊûú„Åå0‰ª∂„ÅÆÂ†¥Âêà„ÅÆË≠¶Âëä
            if len(self.predictions_json) == 0:
                print("\nË≠¶Âëä: ‰∫àÊ∏¨ÁµêÊûú„Åå0‰ª∂„Åß„Åô„ÄÇ„Åô„Åπ„Å¶„ÅÆÁîªÂÉè„ÅßÊé®Ë´ñ„Å´Â§±Êïó„Åó„Åü„Åã„ÄÅÊ§úÂá∫„Åå„ÅÇ„Çä„Åæ„Åõ„Çì„Åß„Åó„Åü„ÄÇ", file=sys.stderr)

            # ‰∫àÊ∏¨ÁµêÊûú‰øùÂ≠ò
            predictions_file = self.save_predictions()
            
            # ‰∫àÊ∏¨„ÅÆ„Åø„É¢„Éº„Éâ„ÅÆÂ†¥Âêà„ÅØ„Åì„Åì„ÅßÁµÇ‰∫Ü
            if self.config.predict_only:
                elapsed_time = time.time() - start_time
                if self.config.verbose >= 1:
                    print(f"\n‰∫àÊ∏¨ÂÆå‰∫Ü (ÁµåÈÅéÊôÇÈñì: {elapsed_time:.2f}Áßí)")
                    print(f"\nCOCOÂΩ¢Âºè„ÅÆ‰∫àÊ∏¨ÁµêÊûú„Çí‰øùÂ≠ò„Åó„Åæ„Åó„Åü: {predictions_file}")
                    print("„Åì„ÅÆ„Éï„Ç°„Ç§„É´„Çí‰Ωø„Å£„Å¶‰ª•‰∏ã„ÅåÂÆüË°å„Åß„Åç„Åæ„Åô:")
                    print(f"  1. Ë©ï‰æ°: sahi coco evaluate --dataset_json_path {self.config.dataset_json_path} --result_json_path {predictions_file}")
                    print(f"  2. „Ç®„É©„ÉºËß£Êûê: sahi coco analyse --dataset_json_path {self.config.dataset_json_path} --result_json_path {predictions_file}")
                
                return {
                    "predictions_file": predictions_file,
                    "num_predictions": len(self.predictions_json),
                    "elapsed_time": elapsed_time
                }

            # Ë©ï‰æ°ÂÆüË°å
            eval_result = self.evaluate(predictions_file)
            
            # eval.json„ÇíÊõ¥Êñ∞ÔºàPrecision/Recall„ÇíËøΩÂä†Ôºâ
            eval_json_path = Path(self.config.output_dir) / "eval.json"
            with open(eval_json_path, 'w', encoding='utf-8') as f:
                json.dump(eval_result['eval_results'], f, indent=4)

            elapsed_time = time.time() - start_time
            if self.config.verbose >= 1:
                print(f"\nValidationÂÆå‰∫Ü (ÁµåÈÅéÊôÇÈñì: {elapsed_time:.2f}Áßí)")

            return eval_result

        except KeyboardInterrupt:
            print("\n\nValidation„Åå‰∏≠Êñ≠„Åï„Çå„Åæ„Åó„Åü", file=sys.stderr)
            sys.exit(130)  # Standard exit code for SIGINT
        except Exception as e:
            print(f"\n„Ç®„É©„Éº„ÅåÁô∫Áîü„Åó„Åæ„Åó„Åü: {e}", file=sys.stderr)
            if self.config.verbose >= 2:
                import traceback
                print(traceback.format_exc(), file=sys.stderr)
            raise


class SAHIValidator:
    """SAHI validator (wrapper around SAHISegmentationValidator)"""
    
    def __init__(self, config: SAHIValidationConfig):
        """
        Args:
            config: SAHI validation configuration
        """
        self.config = config
        self.validator = SAHISegmentationValidator(self.config)
        self.results: Optional[Dict[str, Any]] = None
    
    def validate(self) -> Dict[str, Any]:
        """Run SAHI validation
        
        Returns:
            Validation results dictionary
        """
        if self.config.verbose >= 1:
            print("\n" + "="*70)
            print("SAHI Validation„ÇíÂÆüË°å‰∏≠...")
            print("="*70)
        
        # Run validation
        self.results = self.validator.run()
        
        if self.config.verbose >= 1:
            print("\n" + "="*70)
            print("‚úÖ SAHI ValidationÂÆå‰∫Ü")
            print("="*70)
            self._print_results()
        
        return {
            "output_dir": self.config.output_dir,
            "results": self.results,
            "eval_results": self.results.get("eval_results", {}),
        }
    
    def _print_results(self) -> None:
        """Print validation results"""
        if self.results and "eval_results" in self.results:
            eval_results = self.results["eval_results"]
            
            print("\n=== „É°„Éà„É™„ÇØ„Çπ ===")
            
            # Segmentation metrics
            if "segm_mAP" in eval_results:
                print("\n[Segmentation]")
                print(f"  mAP50-95: {eval_results.get('segm_mAP', 0):.4f} ({eval_results.get('segm_mAP', 0)*100:.2f}%)")
                print(f"  mAP50:    {eval_results.get('segm_mAP50', 0):.4f} ({eval_results.get('segm_mAP50', 0)*100:.2f}%)")
                print(f"  mAP75:    {eval_results.get('segm_mAP75', 0):.4f} ({eval_results.get('segm_mAP75', 0)*100:.2f}%)")
                
                if "segm_precision" in eval_results:
                    print(f"  Precision: {eval_results.get('segm_precision', 0):.4f}")
                if "segm_recall" in eval_results:
                    print(f"  Recall:    {eval_results.get('segm_recall', 0):.4f}")
            
            # Bounding Box metrics
            if "bbox_mAP" in eval_results:
                print("\n[Bounding Box]")
                print(f"  mAP50-95: {eval_results.get('bbox_mAP', 0):.4f} ({eval_results.get('bbox_mAP', 0)*100:.2f}%)")
                print(f"  mAP50:    {eval_results.get('bbox_mAP50', 0):.4f} ({eval_results.get('bbox_mAP50', 0)*100:.2f}%)")
                
                if "bbox_precision" in eval_results:
                    print(f"  Precision: {eval_results.get('bbox_precision', 0):.4f}")
                if "bbox_recall" in eval_results:
                    print(f"  Recall:    {eval_results.get('bbox_recall', 0):.4f}")

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7766792b",
   "metadata": {},
   "source": [
    "## predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "546e09b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã—ã¾ã—ãŸ\n",
      "âœ“ ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ç¢ºèª: D:\\prog_py\\Yolo_trainer\\runs\\train\\train9\\weights\\best.pt\n",
      "âœ“ ç”»åƒãƒ•ã‚©ãƒ«ãƒ€ç¢ºèª: detect_images (13æšã®ç”»åƒ)\n",
      "âœ“ ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ\n",
      "ãƒ¢ãƒ‡ãƒ«ã‚¯ãƒ©ã‚¹æ•°: 1\n",
      "ã‚¯ãƒ©ã‚¹å: ['pod']\n"
     ]
    }
   ],
   "source": [
    "# Ultralyticsã®YOLOv8ã‚’ä½¿ç”¨ã—ã¦ç”»åƒæ¨è«–ã‚’å®Ÿè¡Œ\n",
    "from ultralytics import YOLO\n",
    "import os\n",
    "from pathlib import Path\n",
    "import glob\n",
    "\n",
    "print(\"ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã—ã¾ã—ãŸ\")\n",
    "\n",
    "# ãƒ‘ã‚¹ã®è¨­å®š\n",
    "model_path = r\"D:\\prog_py\\Yolo_trainer\\runs\\train\\train9\\weights\\best.pt\"\n",
    "source_path = \"detect_images\"\n",
    "\n",
    "# ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã¨ç”»åƒãƒ•ã‚©ãƒ«ãƒ€ã®å­˜åœ¨ç¢ºèª\n",
    "if os.path.exists(model_path):\n",
    "    print(f\"âœ“ ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ç¢ºèª: {model_path}\")\n",
    "else:\n",
    "    print(f\"âœ— ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {model_path}\")\n",
    "\n",
    "if os.path.exists(source_path):\n",
    "    images = [f for f in os.listdir(source_path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "    print(f\"âœ“ ç”»åƒãƒ•ã‚©ãƒ«ãƒ€ç¢ºèª: {source_path} ({len(images)}æšã®ç”»åƒ)\")\n",
    "else:\n",
    "    print(f\"âœ— ç”»åƒãƒ•ã‚©ãƒ«ãƒ€ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {source_path}\")\n",
    "\n",
    "# YOLOãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿\n",
    "model = YOLO(model_path)\n",
    "print(f\"âœ“ ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ\")\n",
    "print(f\"ãƒ¢ãƒ‡ãƒ«ã‚¯ãƒ©ã‚¹æ•°: {len(model.names)}\")\n",
    "print(f\"ã‚¯ãƒ©ã‚¹å: {list(model.names.values())}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be6c6340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ¨è«–ã‚’é–‹å§‹ã—ã¾ã™...\n",
      "\n",
      "WARNING imgsz=[1200] must be multiple of max stride 32, updating to [1216]\n",
      "image 1/13 d:\\prog_py\\yolo12_detect\\detect_images\\Image_000003.jpg: 1216x1120 78 pods, 95.4ms\n",
      "image 2/13 d:\\prog_py\\yolo12_detect\\detect_images\\Image_000118.jpg: 1216x736 76 pods, 141.8ms\n",
      "image 3/13 d:\\prog_py\\yolo12_detect\\detect_images\\Image_000188.jpg: 1216x704 58 pods, 82.0ms\n",
      "image 4/13 d:\\prog_py\\yolo12_detect\\detect_images\\Image_000473.jpg: 1216x672 67 pods, 80.5ms\n",
      "image 5/13 d:\\prog_py\\yolo12_detect\\detect_images\\Image_000565.jpg: 1216x512 80 pods, 81.6ms\n",
      "image 6/13 d:\\prog_py\\yolo12_detect\\detect_images\\Image_000896.jpg: 1216x544 58 pods, 77.6ms\n",
      "image 7/13 d:\\prog_py\\yolo12_detect\\detect_images\\Image_001075.jpg: 1216x896 43 pods, 93.9ms\n",
      "image 8/13 d:\\prog_py\\yolo12_detect\\detect_images\\Image_001845.jpg: 1216x480 46 pods, 78.5ms\n",
      "image 9/13 d:\\prog_py\\yolo12_detect\\detect_images\\Image_001851.jpg: 1216x608 17 pods, 77.0ms\n",
      "image 10/13 d:\\prog_py\\yolo12_detect\\detect_images\\Image_001885.jpg: 1216x416 24 pods, 81.5ms\n",
      "image 11/13 d:\\prog_py\\yolo12_detect\\detect_images\\Image_001997.jpg: 1216x640 104 pods, 80.4ms\n",
      "image 12/13 d:\\prog_py\\yolo12_detect\\detect_images\\Image_002005.jpg: 1216x608 58 pods, 21.8ms\n",
      "image 13/13 d:\\prog_py\\yolo12_detect\\detect_images\\Image_002036.jpg: 1216x448 46 pods, 82.2ms\n",
      "Speed: 6.1ms preprocess, 82.6ms inference, 118.7ms postprocess per image at shape (1, 3, 1216, 448)\n",
      "Results saved to \u001b[1mD:\\prog_py\\yolo12_detect\\runs\\detect\\yolo_detection\u001b[0m\n",
      "13 labels saved to D:\\prog_py\\yolo12_detect\\runs\\detect\\yolo_detection\\labels\n",
      "âœ“ æ¨è«–ãŒå®Œäº†ã—ã¾ã—ãŸï¼\n",
      "çµæœã¯ runs/detect/yolo_detection ã«ä¿å­˜ã•ã‚Œã¾ã—ãŸ\n"
     ]
    }
   ],
   "source": [
    "# æŒ‡å®šã•ã‚ŒãŸãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§ç”»åƒæ¨è«–ã‚’å®Ÿè¡Œ\n",
    "print(\"æ¨è«–ã‚’é–‹å§‹ã—ã¾ã™...\")\n",
    "\n",
    "results = model.predict(\n",
    "    source=source_path,      # ç”»åƒãƒ•ã‚©ãƒ«ãƒ€: detect_images\n",
    "    imgsz=1200,              # ç”»åƒã‚µã‚¤ã‚º: 800\n",
    "    save_txt=True,          # ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜: True\n",
    "    line_width=1,           # ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ã®ç·šã®å¤ªã•: 1\n",
    "    save=True,              # æ¨è«–çµæœã®ç”»åƒã‚’ä¿å­˜\n",
    "    conf=0.25,              # ä¿¡é ¼åº¦ã®ã—ãã„å€¤\n",
    "    device='0',           # ãƒ‡ãƒã‚¤ã‚¹ï¼ˆGPUãŒåˆ©ç”¨å¯èƒ½ãªå ´åˆã¯'0'ã«å¤‰æ›´ï¼‰\n",
    "    project='runs/detect',  # çµæœä¿å­˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª\n",
    "    name='yolo_detection',  # å®Ÿé¨“å # æ—¢å­˜ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒã‚ã‚‹å ´åˆä¸Šæ›¸ã\n",
    "    retina_masks=True,\n",
    "    agnostic_nms=True,\n",
    ")\n",
    "\n",
    "print(\"âœ“ æ¨è«–ãŒå®Œäº†ã—ã¾ã—ãŸï¼\")\n",
    "print(f\"çµæœã¯ runs/detect/yolo_detection ã«ä¿å­˜ã•ã‚Œã¾ã—ãŸ\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322475d8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd1114cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ãƒ¢ãƒ‡ãƒ«æ¤œè¨¼ã‚’é–‹å§‹ã—ã¾ã™ ===\n",
      "\n",
      "âœ“ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ç¢ºèª: D:\\Data\\pods\\2025_yolo_pod\\labels\\YOLODataset\\dataset.yaml\n",
      "\n",
      "ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆè¨­å®š:\n",
      "path: \\\\?\\D:\\Data\\pods\\2025_yolo_pod\\labels\\YOLODataset\n",
      "train: images/train\n",
      "val: images/val\n",
      "test:\n",
      "\n",
      "names:\n",
      "    0: pod\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# dataset.yamlã‚’ä½¿ç”¨ã—ãŸãƒ¢ãƒ‡ãƒ«æ¤œè¨¼\n",
    "print(\"=== ãƒ¢ãƒ‡ãƒ«æ¤œè¨¼ã‚’é–‹å§‹ã—ã¾ã™ ===\\n\")\n",
    "\n",
    "# dataset.yamlã®ãƒ‘ã‚¹\n",
    "dataset_yaml_path = r\"D:\\Data\\pods\\2025_yolo_pod\\labels\\YOLODataset\\dataset.yaml\"\n",
    "\n",
    "# dataset.yamlãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ç¢ºèª\n",
    "if os.path.exists(dataset_yaml_path):\n",
    "    print(f\"âœ“ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ç¢ºèª: {dataset_yaml_path}\")\n",
    "    \n",
    "    # ãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹ã‚’è¡¨ç¤º\n",
    "    with open(dataset_yaml_path, 'r', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "        print(f\"\\nãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆè¨­å®š:\")\n",
    "        print(content)\n",
    "else:\n",
    "    print(f\"âœ— ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {dataset_yaml_path}\")\n",
    "    print(\"æ¤œè¨¼ã‚’å®Ÿè¡Œã§ãã¾ã›ã‚“ã€‚\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55c86a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” ç”»åƒã‚µã‚¤ã‚ºï¼ˆ32ã®å€æ•°, 1500ã¾ã§ï¼‰ã§æ¤œè¨¼ã‚’å®Ÿè¡Œã—ã¦ã„ã¾ã™...\n",
      "\n",
      "--- ç”»åƒã‚µã‚¤ã‚º: 512 ã§æ¤œè¨¼ä¸­ ---\n",
      "Ultralytics 8.3.203  Python-3.12.6 torch-2.6.0+cu124 CUDA:0 (NVIDIA GeForce RTX 3060 Laptop GPU, 6144MiB)\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.20.1 ms, read: 27.95.9 MB/s, size: 179.6 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning \\\\?\\D:\\Data\\pods\\2025_yolo_pod\\labels\\YOLODataset\\labels\\val.cache... 13 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13  0.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 0.1it/s 28.6s1:07\n"
     ]
    }
   ],
   "source": [
    "# ç”»åƒã‚µã‚¤ã‚ºï¼ˆimgszï¼‰ã¯max stride 32ã®å€æ•°ã§ã‚°ãƒªãƒƒãƒ‰ã‚µãƒ¼ãƒ\n",
    "if os.path.exists(dataset_yaml_path):\n",
    "    print(\"ğŸ” ç”»åƒã‚µã‚¤ã‚ºï¼ˆ32ã®å€æ•°, 1500ã¾ã§ï¼‰ã§æ¤œè¨¼ã‚’å®Ÿè¡Œã—ã¦ã„ã¾ã™...\")\n",
    "\n",
    "    # 32ã®å€æ•°ã§500ã‹ã‚‰1504ã¾ã§\n",
    "    grid_imgsz = list(range(512, 1505, 32))\n",
    "\n",
    "    for imgsz in grid_imgsz:\n",
    "        print(f\"\\n--- ç”»åƒã‚µã‚¤ã‚º: {imgsz} ã§æ¤œè¨¼ä¸­ ---\")\n",
    "        validation_results = model.val(\n",
    "            data=dataset_yaml_path,\n",
    "            imgsz=imgsz,\n",
    "            plots=True,\n",
    "            batch=8,\n",
    "            save_json=True,\n",
    "            device='0',\n",
    "            project='runs/val',\n",
    "            name=f'val_imgs_{imgsz}',\n",
    "            verbose=True,\n",
    "        )\n",
    "        metrics = getattr(validation_results, 'metrics', None)\n",
    "        if metrics is not None:\n",
    "            map_50_95 = getattr(metrics, 'mAP_0.5_0.95', None)\n",
    "            precision = getattr(metrics, 'precision', None)\n",
    "            recall = getattr(metrics, 'recall', None)\n",
    "            print(f\"  - imgsz={imgsz}: mAP@0.5-0.95={map_50_95}, Precision={precision}, Recall={recall}\")\n",
    "        else:\n",
    "            print(f\"  - imgsz={imgsz}: ãƒ¡ãƒˆãƒªã‚¯ã‚¹å–å¾—ä¸å¯\")\n",
    "\n",
    "else:\n",
    "    print(\"âŒ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚‰ãªã„ãŸã‚ã€æ¤œè¨¼ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a33570",
   "metadata": {},
   "source": [
    "##ã€€å‡ºåŠ›å¤‰æ›"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c58791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.203  Python-3.12.6 torch-2.6.0+cu124 CPU (Intel Core(TM) i7-10875H 2.30GHz)\n",
      "YOLO11s-seg summary (fused): 113 layers, 10,067,203 parameters, 0 gradients, 32.8 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'D:\\prog_py\\Yolo_trainer\\runs\\train\\yolo11s_640\\weights\\best.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) ((1, 37, 8400), (1, 32, 160, 160)) (19.7 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.19.1 opset 19...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.72...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  2.8s, saved as 'D:\\prog_py\\Yolo_trainer\\runs\\train\\yolo11s_640\\weights\\best.onnx' (38.7 MB)\n",
      "\n",
      "Export complete (3.4s)\n",
      "Results saved to \u001b[1mD:\\prog_py\\Yolo_trainer\\runs\\train\\yolo11s_640\\weights\u001b[0m\n",
      "Predict:         yolo predict task=segment model=D:\\prog_py\\Yolo_trainer\\runs\\train\\yolo11s_640\\weights\\best.onnx imgsz=640  \n",
      "Validate:        yolo val task=segment model=D:\\prog_py\\Yolo_trainer\\runs\\train\\yolo11s_640\\weights\\best.onnx imgsz=640 data=D:\\prog_py\\Yolo_trainer\\ultralytic_series\\data\\all_datasets\\inner640_split\\data.yaml  \n",
      "Visualize:       https://netron.app\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'D:\\\\prog_py\\\\Yolo_trainer\\\\runs\\\\train\\\\yolo11s_640\\\\weights\\\\best.onnx'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a model\n",
    "\n",
    "model = YOLO(r\"D:\\prog_py\\Yolo_trainer\\runs\\train\\yolo11s_640\\weights\\best.pt\")  # load a custom trained model\n",
    "\n",
    "# Export the model\n",
    "model.export(format=\"onnx\",\n",
    "             name=\"yolo11s_640_onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4c0ae0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e1204bd8",
   "metadata": {},
   "source": [
    "## auto label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75d4539a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/69 d:\\prog_py\\yolo12_detect\\Dataset\\insta360\\train\\024_01_b.jpg: 640x384 57 pods, 125.5ms\n",
      "image 2/69 d:\\prog_py\\yolo12_detect\\Dataset\\insta360\\train\\024_02_b.jpg: 640x288 63 pods, 78.8ms\n",
      "image 3/69 d:\\prog_py\\yolo12_detect\\Dataset\\insta360\\train\\024_02_f.jpg: 640x384 71 pods, 12.1ms\n",
      "image 4/69 d:\\prog_py\\yolo12_detect\\Dataset\\insta360\\train\\024_03_b.jpg: 640x384 55 pods, 14.3ms\n",
      "image 5/69 d:\\prog_py\\yolo12_detect\\Dataset\\insta360\\train\\024_03_f.jpg: 640x320 64 pods, 92.1ms\n",
      "image 6/69 d:\\prog_py\\yolo12_detect\\Dataset\\insta360\\train\\024_05_b.jpg: 640x320 29 pods, 10.4ms\n",
      "image 7/69 d:\\prog_py\\yolo12_detect\\Dataset\\insta360\\train\\024_05_f.jpg: 640x320 59 pods, 10.0ms\n",
      "image 8/69 d:\\prog_py\\yolo12_detect\\Dataset\\insta360\\train\\043_01_b.jpg: 640x416 66 pods, 90.7ms\n",
      "image 9/69 d:\\prog_py\\yolo12_detect\\Dataset\\insta360\\train\\043_01_f.jpg: 640x512 40 pods, 90.2ms\n",
      "image 10/69 d:\\prog_py\\yolo12_detect\\Dataset\\insta360\\train\\043_05_b.jpg: 640x352 39 pods, 76.9ms\n",
      "image 11/69 d:\\prog_py\\yolo12_detect\\Dataset\\insta360\\train\\043_05_f.jpg: 640x352 38 pods, 11.8ms\n",
      "image 12/69 d:\\prog_py\\yolo12_detect\\Dataset\\insta360\\train\\045_04_b.jpg: 640x448 47 pods, 84.5ms\n",
      "image 13/69 d:\\prog_py\\yolo12_detect\\Dataset\\insta360\\train\\045_04_f.jpg: 640x384 14 pods, 13.0ms\n",
      "image 14/69 d:\\prog_py\\yolo12_detect\\Dataset\\insta360\\train\\045_06_b.jpg: 576x640 32 pods, 78.8ms\n",
      "image 15/69 d:\\prog_py\\yolo12_detect\\Dataset\\insta360\\train\\045_06_f.jpg: 544x640 33 pods, 97.8ms\n",
      "image 16/69 d:\\prog_py\\yolo12_detect\\Dataset\\insta360\\train\\052_01_f.jpg: 640x512 46 pods, 10.6ms\n",
      "image 17/69 d:\\prog_py\\yolo12_detect\\Dataset\\insta360\\train\\052_02_f.jpg: 640x384 37 pods, 13.1ms\n",
      "image 18/69 d:\\prog_py\\yolo12_detect\\Dataset\\insta360\\train\\052_06_b.jpg: 640x384 45 pods, 12.6ms\n",
      "image 19/69 d:\\prog_py\\yolo12_detect\\Dataset\\insta360\\train\\052_06_f.jpg: 640x384 36 pods, 11.7ms\n",
      "image 20/69 d:\\prog_py\\yolo12_detect\\Dataset\\insta360\\train\\057_01_b.jpg: 640x288 34 pods, 11.7ms\n",
      "image 21/69 d:\\prog_py\\yolo12_detect\\Dataset\\insta360\\train\\057_01_f_02jpg.jpg: 640x320 33 pods, 12.5ms\n",
      "image 22/69 d:\\prog_py\\yolo12_detect\\Dataset\\insta360\\train\\057_03_b.jpg: 640x384 72 pods, 11.1ms\n",
      "image 23/69 d:\\prog_py\\yolo12_detect\\Dataset\\insta360\\train\\057_03_f.jpg: 640x416 66 pods, 12.3ms\n",
      "image 24/69 d:\\prog_py\\yolo12_detect\\Dataset\\insta360\\train\\057_04_b.jpg: 640x288 46 pods, 35.9ms\n",
      "image 25/69 d:\\prog_py\\yolo12_detect\\Dataset\\insta360\\train\\057_04_f.jpg: 640x256 39 pods, 78.6ms\n",
      "image 26/69 d:\\prog_py\\yolo12_detect\\Dataset\\insta360\\train\\057_05_b.jpg: 640x544 26 pods, 74.5ms\n",
      "image 27/69 d:\\prog_py\\yolo12_detect\\Dataset\\insta360\\train\\057_05_f.jpg: 640x320 25 pods, 10.7ms\n",
      "image 28/69 d:\\prog_py\\yolo12_detect\\Dataset\\insta360\\train\\057_06_b.jpg: 640x288 45 pods, 11.1ms\n",
      "image 29/69 d:\\prog_py\\yolo12_detect\\Dataset\\insta360\\train\\057_06_f.jpg: 640x416 44 pods, 11.0ms\n",
      "image 30/69 d:\\prog_py\\yolo12_detect\\Dataset\\insta360\\train\\060_01_b.jpg: 640x416 37 pods, 10.7ms\n",
      "image 31/69 d:\\prog_py\\yolo12_detect\\Dataset\\insta360\\train\\060_01_f.jpg: 640x384 48 pods, 11.1ms\n",
      "image 32/69 d:\\prog_py\\yolo12_detect\\Dataset\\insta360\\train\\060_02_b.jpg: 640x352 62 pods, 15.0ms\n",
      "image 33/69 d:\\prog_py\\yolo12_detect\\Dataset\\insta360\\train\\060_02_f.jpg: 640x320 39 pods, 13.6ms\n",
      "image 34/69 d:\\prog_py\\yolo12_detect\\Dataset\\insta360\\train\\060_04_b.jpg: 640x384 48 pods, 11.5ms\n",
      "image 35/69 d:\\prog_py\\yolo12_detect\\Dataset\\insta360\\train\\060_04_f.jpg: 640x288 50 pods, 12.9ms\n",
      "image 36/69 d:\\prog_py\\yolo12_detect\\Dataset\\insta360\\train\\060_05_b.jpg: 640x384 66 pods, 12.6ms\n",
      "image 37/69 d:\\prog_py\\yolo12_detect\\Dataset\\insta360\\train\\060_05_f.jpg: 640x384 57 pods, 12.3ms\n",
      "image 38/69 d:\\prog_py\\yolo12_detect\\Dataset\\insta360\\train\\060_06_b.jpg: 640x416 34 pods, 12.7ms\n",
      "image 39/69 d:\\prog_py\\yolo12_detect\\Dataset\\insta360\\train\\060_06_f.jpg: 640x352 38 pods, 14.3ms\n",
      "image 40/69 d:\\prog_py\\yolo12_detect\\Dataset\\insta360\\train\\111_01_f.jpg: 640x384 62 pods, 12.1ms\n",
      "image 41/69 d:\\prog_py\\yolo12_detect\\Dataset\\insta360\\train\\111_04_b.jpg: 640x384 16 pods, 14.5ms\n",
      "image 42/69 d:\\prog_py\\yolo12_detect\\Dataset\\insta360\\train\\111_04_f.jpg: 640x512 62 pods, 24.0ms\n",
      "image 43/69 d:\\prog_py\\yolo12_detect\\Dataset\\insta360\\train\\135_01_b.jpg: 640x544 58 pods, 14.2ms\n",
      "image 44/69 d:\\prog_py\\yolo12_detect\\Dataset\\insta360\\train\\135_01or02_f.jpg: 640x256 42 pods, 11.9ms\n",
      "image 45/69 d:\\prog_py\\yolo12_detect\\Dataset\\insta360\\train\\135_02_b.jpg: 640x288 56 pods, 11.5ms\n",
      "image 46/69 d:\\prog_py\\yolo12_detect\\Dataset\\insta360\\train\\135_02or03_b.jpg: 640x512 44 pods, 140.6ms\n",
      "image 47/69 d:\\prog_py\\yolo12_detect\\Dataset\\insta360\\train\\135_02or03_f.jpg: 640x320 47 pods, 10.9ms\n",
      "image 48/69 d:\\prog_py\\yolo12_detect\\Dataset\\insta360\\train\\135_05_b.jpg: 640x352 45 pods, 10.8ms\n",
      "image 49/69 d:\\prog_py\\yolo12_detect\\Dataset\\insta360\\train\\135_05_f.jpg: 640x384 29 pods, 13.4ms\n",
      "image 50/69 d:\\prog_py\\yolo12_detect\\Dataset\\insta360\\train\\135_06_b.jpg: 640x352 34 pods, 11.2ms\n",
      "image 51/69 d:\\prog_py\\yolo12_detect\\Dataset\\insta360\\train\\135_06_f.jpg: 640x384 49 pods, 12.7ms\n",
      "image 52/69 d:\\prog_py\\yolo12_detect\\Dataset\\insta360\\train\\139_02_b.jpg: 640x384 41 pods, 13.7ms\n",
      "image 53/69 d:\\prog_py\\yolo12_detect\\Dataset\\insta360\\train\\139_02_f.jpg: 640x320 68 pods, 10.7ms\n",
      "image 54/69 d:\\prog_py\\yolo12_detect\\Dataset\\insta360\\train\\139_05_b.jpg: 640x384 29 pods, 13.0ms\n",
      "image 55/69 d:\\prog_py\\yolo12_detect\\Dataset\\insta360\\train\\139_05_f.jpg: 640x384 73 pods, 11.5ms\n",
      "image 56/69 d:\\prog_py\\yolo12_detect\\Dataset\\insta360\\train\\139_06_b.jpg: 640x416 46 pods, 11.0ms\n",
      "image 57/69 d:\\prog_py\\yolo12_detect\\Dataset\\insta360\\train\\139_06_f.jpg: 640x352 57 pods, 13.6ms\n",
      "image 58/69 d:\\prog_py\\yolo12_detect\\Dataset\\insta360\\train\\144_02_b.jpg: 640x320 36 pods, 13.2ms\n",
      "image 59/69 d:\\prog_py\\yolo12_detect\\Dataset\\insta360\\train\\144_02_f.jpg: 640x288 60 pods, 15.1ms\n",
      "image 60/69 d:\\prog_py\\yolo12_detect\\Dataset\\insta360\\train\\144_04_b.jpg: 640x352 14 pods, 12.7ms\n",
      "image 61/69 d:\\prog_py\\yolo12_detect\\Dataset\\insta360\\train\\144_04_f.jpg: 640x320 46 pods, 12.9ms\n",
      "image 62/69 d:\\prog_py\\yolo12_detect\\Dataset\\insta360\\train\\144_05_b.jpg: 640x288 26 pods, 11.2ms\n",
      "image 63/69 d:\\prog_py\\yolo12_detect\\Dataset\\insta360\\train\\144_05_f.jpg: 640x384 43 pods, 11.4ms\n",
      "image 64/69 d:\\prog_py\\yolo12_detect\\Dataset\\insta360\\train\\144_06_b.jpg: 640x448 43 pods, 12.3ms\n",
      "image 65/69 d:\\prog_py\\yolo12_detect\\Dataset\\insta360\\train\\144_06_fjpg.jpg: 640x384 46 pods, 19.4ms\n",
      "image 66/69 d:\\prog_py\\yolo12_detect\\Dataset\\insta360\\train\\162_05_b.jpg: 640x480 53 pods, 89.2ms\n",
      "image 67/69 d:\\prog_py\\yolo12_detect\\Dataset\\insta360\\train\\162_05_f.jpg: 640x416 66 pods, 11.3ms\n",
      "image 68/69 d:\\prog_py\\yolo12_detect\\Dataset\\insta360\\train\\162_06_b.jpg: 640x480 28 pods, 11.5ms\n",
      "image 69/69 d:\\prog_py\\yolo12_detect\\Dataset\\insta360\\train\\162_06_f.jpg: 640x448 64 pods, 16.2ms\n",
      "Speed: 2.3ms preprocess, 28.0ms inference, 51.9ms postprocess per image at shape (1, 3, 640, 448)\n"
     ]
    }
   ],
   "source": [
    "from ultralytics.data.annotator import auto_annotate\n",
    "\n",
    "auto_annotate(data=r\"Dataset\\insta360\\train\",\n",
    "              det_model=r\"D:\\prog_py\\Yolo_trainer\\runs\\train\\yolo11s_640\\weights\\best.pt\",\n",
    "              sam_model=\"sam2.1_l.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

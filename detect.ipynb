{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7766792b",
   "metadata": {},
   "source": [
    "## predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "546e09b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã—ã¾ã—ãŸ\n",
      "âœ— ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: D:\\prog_py\\Yolo_trainer\\runs\\train\\train9\\weights\\best.pt\n",
      "âœ“ ç”»åƒãƒ•ã‚©ãƒ«ãƒ€ç¢ºèª: detect_images (13æšã®ç”»åƒ)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x000001FBCB47CFE0>\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\prog_py\\yolo12_detect\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 1618, in __del__\n",
      "  File \"d:\\prog_py\\yolo12_detect\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 1576, in _shutdown_workers\n",
      "AttributeError: '_MultiProcessingDataLoaderIter' object has no attribute '_workers_status'\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'D:\\\\prog_py\\\\Yolo_trainer\\\\runs\\\\train\\\\train9\\\\weights\\\\best.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 26\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mâœ— ç”»åƒãƒ•ã‚©ãƒ«ãƒ€ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msource_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# YOLOãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mYOLO\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mâœ“ ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mãƒ¢ãƒ‡ãƒ«ã‚¯ãƒ©ã‚¹æ•°: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(model\u001b[38;5;241m.\u001b[39mnames)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\prog_py\\yolo12_detect\\.venv\\Lib\\site-packages\\ultralytics\\models\\yolo\\model.py:83\u001b[0m, in \u001b[0;36mYOLO.__init__\u001b[1;34m(self, model, task, verbose)\u001b[0m\n\u001b[0;32m     80\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m \u001b[38;5;241m=\u001b[39m new_instance\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     82\u001b[0m     \u001b[38;5;66;03m# Continue with default YOLO initialization\u001b[39;00m\n\u001b[1;32m---> 83\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     84\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRTDETR\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mmodel[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39m_get_name():  \u001b[38;5;66;03m# if RTDETR head\u001b[39;00m\n\u001b[0;32m     85\u001b[0m         \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01multralytics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RTDETR\n",
      "File \u001b[1;32md:\\prog_py\\yolo12_detect\\.venv\\Lib\\site-packages\\ultralytics\\engine\\model.py:153\u001b[0m, in \u001b[0;36mModel.__init__\u001b[1;34m(self, model, task, verbose)\u001b[0m\n\u001b[0;32m    151\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_new(model, task\u001b[38;5;241m=\u001b[39mtask, verbose\u001b[38;5;241m=\u001b[39mverbose)\n\u001b[0;32m    152\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 153\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;66;03m# Delete super().training for accessing self.model.training\u001b[39;00m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining\n",
      "File \u001b[1;32md:\\prog_py\\yolo12_detect\\.venv\\Lib\\site-packages\\ultralytics\\engine\\model.py:297\u001b[0m, in \u001b[0;36mModel._load\u001b[1;34m(self, weights, task)\u001b[0m\n\u001b[0;32m    294\u001b[0m weights \u001b[38;5;241m=\u001b[39m checks\u001b[38;5;241m.\u001b[39mcheck_model_file_from_stem(weights)  \u001b[38;5;66;03m# add suffix, i.e. yolo11n -> yolo11n.pt\u001b[39;00m\n\u001b[0;32m    296\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(weights)\u001b[38;5;241m.\u001b[39mrpartition(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 297\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mckpt \u001b[38;5;241m=\u001b[39m \u001b[43mload_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweights\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    298\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mtask\n\u001b[0;32m    299\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moverrides \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39margs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset_ckpt_args(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39margs)\n",
      "File \u001b[1;32md:\\prog_py\\yolo12_detect\\.venv\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:1501\u001b[0m, in \u001b[0;36mload_checkpoint\u001b[1;34m(weight, device, inplace, fuse)\u001b[0m\n\u001b[0;32m   1487\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mload_checkpoint\u001b[39m(weight, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, fuse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m   1488\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1489\u001b[0m \u001b[38;5;124;03m    Load a single model weights.\u001b[39;00m\n\u001b[0;32m   1490\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1499\u001b[0m \u001b[38;5;124;03m        ckpt (dict): Model checkpoint dictionary.\u001b[39;00m\n\u001b[0;32m   1500\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1501\u001b[0m     ckpt, weight \u001b[38;5;241m=\u001b[39m \u001b[43mtorch_safe_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# load ckpt\u001b[39;00m\n\u001b[0;32m   1502\u001b[0m     args \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mDEFAULT_CFG_DICT, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m(ckpt\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_args\u001b[39m\u001b[38;5;124m\"\u001b[39m, {}))}  \u001b[38;5;66;03m# combine model and default args, preferring model args\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m     model \u001b[38;5;241m=\u001b[39m (ckpt\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mema\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m ckpt[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mfloat()  \u001b[38;5;66;03m# FP32 model\u001b[39;00m\n",
      "File \u001b[1;32md:\\prog_py\\yolo12_detect\\.venv\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:1448\u001b[0m, in \u001b[0;36mtorch_safe_load\u001b[1;34m(weight, safe_only)\u001b[0m\n\u001b[0;32m   1446\u001b[0m                 ckpt \u001b[38;5;241m=\u001b[39m torch_load(f, pickle_module\u001b[38;5;241m=\u001b[39msafe_pickle)\n\u001b[0;32m   1447\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1448\u001b[0m             ckpt \u001b[38;5;241m=\u001b[39m \u001b[43mtorch_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1450\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# e.name is missing module name\u001b[39;00m\n\u001b[0;32m   1451\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m e\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodels\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32md:\\prog_py\\yolo12_detect\\.venv\\Lib\\site-packages\\ultralytics\\utils\\patches.py:120\u001b[0m, in \u001b[0;36mtorch_load\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m TORCH_1_13 \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweights_only\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[0;32m    118\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweights_only\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 120\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\prog_py\\yolo12_detect\\.venv\\Lib\\site-packages\\torch\\serialization.py:1425\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[0;32m   1422\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m   1423\u001b[0m     pickle_load_args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1425\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[0;32m   1426\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[0;32m   1427\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[0;32m   1428\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[0;32m   1429\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[0;32m   1430\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[1;32md:\\prog_py\\yolo12_detect\\.venv\\Lib\\site-packages\\torch\\serialization.py:751\u001b[0m, in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    749\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[0;32m    750\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[1;32m--> 751\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    752\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    753\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[1;32md:\\prog_py\\yolo12_detect\\.venv\\Lib\\site-packages\\torch\\serialization.py:732\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[1;34m(self, name, mode)\u001b[0m\n\u001b[0;32m    731\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[1;32m--> 732\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'D:\\\\prog_py\\\\Yolo_trainer\\\\runs\\\\train\\\\train9\\\\weights\\\\best.pt'"
     ]
    }
   ],
   "source": [
    "# Ultralyticsã®YOLOv8ã‚’ä½¿ç”¨ã—ã¦ç”»åƒæ¨è«–ã‚’å®Ÿè¡Œ\n",
    "from ultralytics import YOLO\n",
    "import os\n",
    "from pathlib import Path\n",
    "import glob\n",
    "\n",
    "print(\"ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã—ã¾ã—ãŸ\")\n",
    "\n",
    "# ãƒ‘ã‚¹ã®è¨­å®š\n",
    "model_path = r\"D:\\prog_py\\Yolo_trainer\\runs\\train\\train9\\weights\\best.pt\"\n",
    "source_path = \"detect_images\"\n",
    "\n",
    "# ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã¨ç”»åƒãƒ•ã‚©ãƒ«ãƒ€ã®å­˜åœ¨ç¢ºèª\n",
    "if os.path.exists(model_path):\n",
    "    print(f\"âœ“ ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ç¢ºèª: {model_path}\")\n",
    "else:\n",
    "    print(f\"âœ— ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {model_path}\")\n",
    "\n",
    "if os.path.exists(source_path):\n",
    "    images = [f for f in os.listdir(source_path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "    print(f\"âœ“ ç”»åƒãƒ•ã‚©ãƒ«ãƒ€ç¢ºèª: {source_path} ({len(images)}æšã®ç”»åƒ)\")\n",
    "else:\n",
    "    print(f\"âœ— ç”»åƒãƒ•ã‚©ãƒ«ãƒ€ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {source_path}\")\n",
    "\n",
    "# YOLOãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿\n",
    "model = YOLO(model_path)\n",
    "print(f\"âœ“ ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ\")\n",
    "print(f\"ãƒ¢ãƒ‡ãƒ«ã‚¯ãƒ©ã‚¹æ•°: {len(model.names)}\")\n",
    "print(f\"ã‚¯ãƒ©ã‚¹å: {list(model.names.values())}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6c6340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ¨è«–ã‚’é–‹å§‹ã—ã¾ã™...\n",
      "\n",
      "WARNING imgsz=[1200] must be multiple of max stride 32, updating to [1216]\n",
      "image 1/13 d:\\prog_py\\yolo12_detect\\detect_images\\Image_000003.jpg: 1216x1120 74 pods, 93.1ms\n",
      "image 2/13 d:\\prog_py\\yolo12_detect\\detect_images\\Image_000118.jpg: 1216x736 74 pods, 87.3ms\n",
      "image 3/13 d:\\prog_py\\yolo12_detect\\detect_images\\Image_000188.jpg: 1216x704 52 pods, 84.4ms\n",
      "image 4/13 d:\\prog_py\\yolo12_detect\\detect_images\\Image_000473.jpg: 1216x672 69 pods, 96.4ms\n",
      "image 5/13 d:\\prog_py\\yolo12_detect\\detect_images\\Image_000565.jpg: 1216x512 70 pods, 80.5ms\n",
      "image 6/13 d:\\prog_py\\yolo12_detect\\detect_images\\Image_000896.jpg: 1216x544 56 pods, 113.4ms\n",
      "image 7/13 d:\\prog_py\\yolo12_detect\\detect_images\\Image_001075.jpg: 1216x896 39 pods, 111.7ms\n",
      "image 8/13 d:\\prog_py\\yolo12_detect\\detect_images\\Image_001845.jpg: 1216x480 41 pods, 88.5ms\n",
      "image 9/13 d:\\prog_py\\yolo12_detect\\detect_images\\Image_001851.jpg: 1216x608 15 pods, 81.0ms\n",
      "image 10/13 d:\\prog_py\\yolo12_detect\\detect_images\\Image_001885.jpg: 1216x416 24 pods, 79.2ms\n",
      "image 11/13 d:\\prog_py\\yolo12_detect\\detect_images\\Image_001997.jpg: 1216x640 97 pods, 87.4ms\n",
      "image 12/13 d:\\prog_py\\yolo12_detect\\detect_images\\Image_002005.jpg: 1216x608 50 pods, 15.9ms\n",
      "image 13/13 d:\\prog_py\\yolo12_detect\\detect_images\\Image_002036.jpg: 1216x448 44 pods, 118.6ms\n",
      "Speed: 7.0ms preprocess, 87.5ms inference, 205.0ms postprocess per image at shape (1, 3, 1216, 448)\n",
      "Results saved to \u001b[1mD:\\prog_py\\yolo12_detect\\runs\\detect\\yolo_detection18\u001b[0m\n",
      "13 labels saved to D:\\prog_py\\yolo12_detect\\runs\\detect\\yolo_detection18\\labels\n",
      "âœ“ æ¨è«–ãŒå®Œäº†ã—ã¾ã—ãŸï¼\n",
      "çµæœã¯ runs/detect/yolo_detection ã«ä¿å­˜ã•ã‚Œã¾ã—ãŸ\n"
     ]
    }
   ],
   "source": [
    "# æŒ‡å®šã•ã‚ŒãŸãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§ç”»åƒæ¨è«–ã‚’å®Ÿè¡Œ\n",
    "print(\"æ¨è«–ã‚’é–‹å§‹ã—ã¾ã™...\")\n",
    "\n",
    "results = model.predict(\n",
    "    source=source_path,      # ç”»åƒãƒ•ã‚©ãƒ«ãƒ€: detect_images\n",
    "    imgsz=1200,              # ç”»åƒã‚µã‚¤ã‚º: 800\n",
    "    save_txt=True,          # ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜: True\n",
    "    line_width=1,           # ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ã®ç·šã®å¤ªã•: 1\n",
    "    save=True,              # æ¨è«–çµæœã®ç”»åƒã‚’ä¿å­˜\n",
    "    conf=0.25,              # ä¿¡é ¼åº¦ã®ã—ãã„å€¤\n",
    "    device='0',           # ãƒ‡ãƒã‚¤ã‚¹ï¼ˆGPUãŒåˆ©ç”¨å¯èƒ½ãªå ´åˆã¯'0'ã«å¤‰æ›´ï¼‰\n",
    "    project='runs/detect',  # çµæœä¿å­˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª\n",
    "    name='yolo_detection',  # å®Ÿé¨“å # æ—¢å­˜ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒã‚ã‚‹å ´åˆä¸Šæ›¸ã\n",
    "    retina_masks=True,\n",
    "    agnostic_nms=True,\n",
    ")\n",
    "\n",
    "print(\"âœ“ æ¨è«–ãŒå®Œäº†ã—ã¾ã—ãŸï¼\")\n",
    "print(f\"çµæœã¯ runs/detect/yolo_detection ã«ä¿å­˜ã•ã‚Œã¾ã—ãŸ\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322475d8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1114cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ãƒ¢ãƒ‡ãƒ«æ¤œè¨¼ã‚’é–‹å§‹ã—ã¾ã™ ===\n",
      "\n",
      "âœ“ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ç¢ºèª: D:\\Data\\pods\\2025_yolo_pod\\labels\\YOLODataset\\dataset.yaml\n",
      "\n",
      "ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆè¨­å®š:\n",
      "path: \\\\?\\D:\\Data\\pods\\2025_yolo_pod\\labels\\YOLODataset\n",
      "train: images/train\n",
      "val: images/val\n",
      "test:\n",
      "\n",
      "names:\n",
      "    0: pod\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# dataset.yamlã‚’ä½¿ç”¨ã—ãŸãƒ¢ãƒ‡ãƒ«æ¤œè¨¼\n",
    "print(\"=== ãƒ¢ãƒ‡ãƒ«æ¤œè¨¼ã‚’é–‹å§‹ã—ã¾ã™ ===\\n\")\n",
    "\n",
    "# dataset.yamlã®ãƒ‘ã‚¹\n",
    "dataset_yaml_path = r\"D:\\Data\\pods\\2025_yolo_pod\\labels\\YOLODataset\\dataset.yaml\"\n",
    "\n",
    "# dataset.yamlãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ç¢ºèª\n",
    "if os.path.exists(dataset_yaml_path):\n",
    "    print(f\"âœ“ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ç¢ºèª: {dataset_yaml_path}\")\n",
    "    \n",
    "    # ãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹ã‚’è¡¨ç¤º\n",
    "    with open(dataset_yaml_path, 'r', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "        print(f\"\\nãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆè¨­å®š:\")\n",
    "        print(content)\n",
    "else:\n",
    "    print(f\"âœ— ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {dataset_yaml_path}\")\n",
    "    print(\"æ¤œè¨¼ã‚’å®Ÿè¡Œã§ãã¾ã›ã‚“ã€‚\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55c86a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç”»åƒã‚µã‚¤ã‚ºï¼ˆimgszï¼‰ã¯max stride 32ã®å€æ•°ã§ã‚°ãƒªãƒƒãƒ‰ã‚µãƒ¼ãƒ\n",
    "if os.path.exists(dataset_yaml_path):\n",
    "    print(\"ğŸ” ç”»åƒã‚µã‚¤ã‚ºï¼ˆ32ã®å€æ•°, 1500ã¾ã§ï¼‰ã§æ¤œè¨¼ã‚’å®Ÿè¡Œã—ã¦ã„ã¾ã™...\")\n",
    "\n",
    "    # 32ã®å€æ•°ã§500ã‹ã‚‰1504ã¾ã§\n",
    "    grid_imgsz = list(range(512, 1505, 32))\n",
    "\n",
    "    for imgsz in grid_imgsz:\n",
    "        print(f\"\\n--- ç”»åƒã‚µã‚¤ã‚º: {imgsz} ã§æ¤œè¨¼ä¸­ ---\")\n",
    "        validation_results = model.val(\n",
    "            data=dataset_yaml_path,\n",
    "            imgsz=imgsz,\n",
    "            plots=True,\n",
    "            batch=8,\n",
    "            save_json=True,\n",
    "            device='0',\n",
    "            project='runs/val',\n",
    "            name=f'val_imgs_{imgsz}',\n",
    "            verbose=True,\n",
    "        )\n",
    "        metrics = getattr(validation_results, 'metrics', None)\n",
    "        if metrics is not None:\n",
    "            map_50_95 = getattr(metrics, 'mAP_0.5_0.95', None)\n",
    "            precision = getattr(metrics, 'precision', None)\n",
    "            recall = getattr(metrics, 'recall', None)\n",
    "            print(f\"  - imgsz={imgsz}: mAP@0.5-0.95={map_50_95}, Precision={precision}, Recall={recall}\")\n",
    "        else:\n",
    "            print(f\"  - imgsz={imgsz}: ãƒ¡ãƒˆãƒªã‚¯ã‚¹å–å¾—ä¸å¯\")\n",
    "\n",
    "else:\n",
    "    print(\"âŒ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚‰ãªã„ãŸã‚ã€æ¤œè¨¼ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a33570",
   "metadata": {},
   "source": [
    "##ã€€å‡ºåŠ›å¤‰æ›"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "47c58791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.203  Python-3.12.6 torch-2.6.0+cu124 CPU (Intel Core(TM) i7-10875H 2.30GHz)\n",
      " ProTip: Export to OpenVINO format for best performance on Intel hardware. Learn more at https://docs.ultralytics.com/integrations/openvino/\n",
      "YOLO11s-seg summary (fused): 113 layers, 10,067,203 parameters, 0 gradients, 32.8 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'D:\\prog_py\\Yolo_trainer\\runs\\train\\yolo11_split\\weights\\best.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) ((1, 37, 8400), (1, 32, 160, 160)) (19.7 MB)\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirements ['onnx>=1.12.0', 'onnxslim>=0.1.67', 'onnxruntime-gpu'] not found, attempting AutoUpdate...\n",
      "\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success  37.7s\n",
      "WARNING \u001b[31m\u001b[1mrequirements:\u001b[0m \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.19.1 opset 19...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.72...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  42.3s, saved as 'D:\\prog_py\\Yolo_trainer\\runs\\train\\yolo11_split\\weights\\best.onnx' (38.7 MB)\n",
      "\n",
      "Export complete (43.1s)\n",
      "Results saved to \u001b[1mD:\\prog_py\\Yolo_trainer\\runs\\train\\yolo11_split\\weights\u001b[0m\n",
      "Predict:         yolo predict task=segment model=D:\\prog_py\\Yolo_trainer\\runs\\train\\yolo11_split\\weights\\best.onnx imgsz=640  \n",
      "Validate:        yolo val task=segment model=D:\\prog_py\\Yolo_trainer\\runs\\train\\yolo11_split\\weights\\best.onnx imgsz=640 data=D:\\prog_py\\Yolo_trainer\\ultralytic_series\\data\\all_datasets\\Yolo_split\\data.yaml  \n",
      "Visualize:       https://netron.app\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'D:\\\\prog_py\\\\Yolo_trainer\\\\runs\\\\train\\\\yolo11_split\\\\weights\\\\best.onnx'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a model\n",
    "\n",
    "model = YOLO(r\"D:\\prog_py\\Yolo_trainer\\runs\\train\\yolo11_split\\weights\\best.pt\")  # load a custom trained model\n",
    "\n",
    "# Export the model\n",
    "model.export(format=\"onnx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

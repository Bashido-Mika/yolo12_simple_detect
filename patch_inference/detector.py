"""
Patch-based detection module
"""

import cv2
import os
import csv
from pathlib import Path
from collections import Counter
from ultralytics import YOLO
from patched_yolo_infer import MakeCropsDetectThem, CombineDetections, visualize_results


def save_detections_to_csv(detections_data, output_path, verbose=True):
    """
    æ¤œå‡ºçµæœã‚’CSVãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
    
    Args:
        detections_data: æ¤œå‡ºçµæœã®ãƒªã‚¹ãƒˆ
        output_path: CSVå‡ºåŠ›ãƒ‘ã‚¹
        verbose: è©³ç´°å‡ºåŠ›
    """
    if not detections_data:
        if verbose:
            print("âš ï¸  ä¿å­˜ã™ã‚‹æ¤œå‡ºçµæœãŒã‚ã‚Šã¾ã›ã‚“")
        return
    
    # CSVãƒ˜ãƒƒãƒ€ãƒ¼
    fieldnames = [
        'image_name',
        'object_id',
        'class_name',
        'class_id',
        'confidence',
        'x1',
        'y1',
        'x2',
        'y2',
        'width',
        'height',
        'center_x',
        'center_y'
    ]
    
    with open(output_path, 'w', newline='', encoding='utf-8') as csvfile:
        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
        writer.writeheader()
        
        total_detections = 0
        for img_data in detections_data:
            image_name = Path(img_data['path']).name
            result = img_data['result']
            
            boxes = result.filtered_boxes
            confidences = result.filtered_confidences
            classes_ids = result.filtered_classes_id
            classes_names = result.filtered_classes_names
            
            for obj_id, (box, conf, cls_id, cls_name) in enumerate(
                zip(boxes, confidences, classes_ids, classes_names), start=1
            ):
                x1, y1, x2, y2 = box
                width = x2 - x1
                height = y2 - y1
                center_x = (x1 + x2) / 2
                center_y = (y1 + y2) / 2
                
                writer.writerow({
                    'image_name': image_name,
                    'object_id': obj_id,
                    'class_name': cls_name,
                    'class_id': int(cls_id),
                    'confidence': float(conf),
                    'x1': float(x1),
                    'y1': float(y1),
                    'x2': float(x2),
                    'y2': float(y2),
                    'width': float(width),
                    'height': float(height),
                    'center_x': float(center_x),
                    'center_y': float(center_y)
                })
                total_detections += 1
    
    if verbose:
        print(f"ğŸ“Š CSVä¿å­˜å®Œäº†: {output_path}")
        print(f"   ç·æ¤œå‡ºæ•°: {total_detections}å€‹")


def run_patch_detection(
    model_path,
    source_path,
    output_dir,
    shape_x=400,
    shape_y=400,
    overlap_x=30,
    overlap_y=30,
    conf_threshold=0.5,
    imgsz=640,
    nms_threshold=0.3,
    batch_inference=True,
    verbose=True,
    show_boxes=True,
    show_class=False,
    show_confidences=True,
    fill_mask=True,
    alpha=0.7,
    thickness=2,
    font_scale=2.0,
    random_object_colors=True,
    save_csv=False,
    csv_path=None
):
    """
    ãƒ‘ãƒƒãƒãƒ™ãƒ¼ã‚¹ã®æ¤œå‡ºã‚’å®Ÿè¡Œ
    
    Args:
        model_path: YOLOãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ã‚¹
        source_path: ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã¾ãŸã¯ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ãƒ‘ã‚¹
        output_dir: å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        shape_x: ãƒ‘ãƒƒãƒã®å¹…
        shape_y: ãƒ‘ãƒƒãƒã®é«˜ã•
        overlap_x: Xè»¸ã‚ªãƒ¼ãƒãƒ¼ãƒ©ãƒƒãƒ— (%)
        overlap_y: Yè»¸ã‚ªãƒ¼ãƒãƒ¼ãƒ©ãƒƒãƒ— (%)
        conf_threshold: ä¿¡é ¼åº¦é–¾å€¤
        imgsz: YOLOå…¥åŠ›ã‚µã‚¤ã‚º
        nms_threshold: NMSé–¾å€¤
        batch_inference: ãƒãƒƒãƒæ¨è«–ã‚’æœ‰åŠ¹åŒ–
        verbose: è©³ç´°å‡ºåŠ›
        show_boxes: ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ã‚’æç”»ã™ã‚‹ã‹
        show_class: ã‚¯ãƒ©ã‚¹ãƒ©ãƒ™ãƒ«ã‚’è¡¨ç¤ºã™ã‚‹ã‹
        show_confidences: ä¿¡é ¼åº¦ã‚¹ã‚³ã‚¢ã‚’è¡¨ç¤ºã™ã‚‹ã‹
        fill_mask: ãƒã‚¹ã‚¯ã‚’å¡—ã‚Šã¤ã¶ã™ã‹
        alpha: ãƒã‚¹ã‚¯é€æ˜åº¦
        thickness: ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ã®ç·šå¹…
        font_scale: ãƒ©ãƒ™ãƒ«è¡¨ç¤ºæ™‚ã®æ–‡å­—ã‚µã‚¤ã‚º
        random_object_colors: ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã”ã¨ã«ãƒ©ãƒ³ãƒ€ãƒ ãªè‰²ã‚’ä½¿ç”¨ã™ã‚‹ã‹
        save_csv: CSVå½¢å¼ã§æ¤œå‡ºçµæœã‚’ä¿å­˜ã™ã‚‹ã‹
        csv_path: CSVå‡ºåŠ›ãƒ‘ã‚¹ï¼ˆNoneã®å ´åˆã¯è‡ªå‹•ç”Ÿæˆï¼‰

    Returns:
        å‡¦ç†ã—ãŸç”»åƒã®ãƒªã‚¹ãƒˆ, å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
    """
    # ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿
    if verbose:
        print(f"ğŸ“¦ ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿: {model_path}")
    model = YOLO(model_path)
    
    # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’é€£ç•ªã§ä½œæˆ
    base_dir = output_dir
    i = 1
    while True:
        output_dir = f"{base_dir}{i}" if i > 1 else base_dir
        if not os.path.exists(output_dir):
            os.makedirs(output_dir, exist_ok=True)
            break
        i += 1
    
    # ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒªã‚¹ãƒˆã‚’å–å¾—
    if os.path.isfile(source_path):
        image_files = [source_path]
    else:
        image_files = []
        for ext in ['*.jpg', '*.jpeg', '*.png', '*.bmp']:
            image_files.extend(Path(source_path).glob(ext))
        image_files = sorted([str(f) for f in image_files])
    
    if not image_files:
        print(f"âŒ ç”»åƒãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {source_path}")
        return []
    
    if verbose:
        print(f"\nâš™ï¸  è¨­å®š:")
        print(f"  ãƒ‘ãƒƒãƒã‚µã‚¤ã‚º: {shape_x}x{shape_y}")
        print(f"  ã‚ªãƒ¼ãƒãƒ¼ãƒ©ãƒƒãƒ—: {overlap_x}% x {overlap_y}%")
        print(f"  ä¿¡é ¼åº¦é–¾å€¤: {conf_threshold}")
        print(f"  NMSé–¾å€¤: {nms_threshold}")
        print(f"  ãƒãƒƒãƒæ¨è«–: {'æœ‰åŠ¹' if batch_inference else 'ç„¡åŠ¹'}")
        print(f"  ç”»åƒæ•°: {len(image_files)}æš")
        print(f"  ä¿å­˜å…ˆ: {output_dir}\n")
    
    # å„ç”»åƒã«å¯¾ã—ã¦æ¨è«–ã‚’å®Ÿè¡Œ
    processed_images = []
    
    for idx, img_path in enumerate(image_files):
        if verbose:
            print(f"[{idx+1}/{len(image_files)}] {Path(img_path).name}")
        
        img = cv2.imread(img_path)
        if img is None:
            print(f"  âŒ ã‚¨ãƒ©ãƒ¼: èª­ã¿è¾¼ã¿å¤±æ•—")
            continue
        
        # ãƒ‘ãƒƒãƒãƒ™ãƒ¼ã‚¹æ¨è«–
        element_crops = MakeCropsDetectThem(
            image=img,
            model=model,
            segment=True,
            shape_x=shape_x,
            shape_y=shape_y,
            overlap_x=overlap_x,
            overlap_y=overlap_y,
            conf=conf_threshold,
            imgsz=imgsz,
            show_crops=False,
            memory_optimize=False,
            batch_inference=batch_inference,
            show_processing_status=False,
        )
        
        # çµæœçµåˆã¨NMS
        result = CombineDetections(
            element_crops, 
            nms_threshold=nms_threshold,
            class_agnostic_nms=True,  # ã‚¯ãƒ©ã‚¹é–“ã§ã‚‚NMSã‚’é©ç”¨
        )
        
        # æ¤œå‡ºçµæœ
        confidences = result.filtered_confidences
        boxes = result.filtered_boxes
        masks = result.filtered_masks
        classes_ids = result.filtered_classes_id
        classes_names = result.filtered_classes_names
        
        # çµæœè¡¨ç¤º
        if verbose:
            class_counts = Counter(classes_names)
            for class_name, count in class_counts.items():
                print(f"  {class_name}: {count}å€‹")
        
        # å¯è¦–åŒ–
        result_img = visualize_results(
            img=img,
            boxes=boxes,
            classes_ids=classes_ids,
            confidences=confidences,
            classes_names=classes_names,
            masks=masks,
            segment=True,
            show_boxes=show_boxes,
            show_class=show_class,
            fill_mask=fill_mask,
            alpha=alpha,
            thickness=thickness,
            font_scale=font_scale,
            show_confidences=show_confidences,
            return_image_array=True,
            random_object_colors=random_object_colors,
        )
        
        # ä¿å­˜
        output_path = os.path.join(output_dir, Path(img_path).name)
        cv2.imwrite(output_path, result_img)
        
        processed_images.append({
            'path': img_path,
            'output_path': output_path,
            'detections': len(confidences),
            'element_crops': element_crops,
            'result': result
        })
    
    if verbose:
        print(f"\nâœ… å®Œäº†ï¼çµæœ: {output_dir}")
    
    # CSVä¿å­˜
    if save_csv and processed_images:
        if csv_path is None:
            csv_path = os.path.join(output_dir, 'detections.csv')
        save_detections_to_csv(processed_images, csv_path, verbose=verbose)
    
    return processed_images, output_dir

